{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\naida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\naida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\naida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (1.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\naida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\naida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\naida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\naida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.13.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\naida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\naida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (3.4.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\naida\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best parameters for SVR: {'svr__C': 100, 'svr__gamma': 0.1, 'svr__kernel': 'linear'}\n",
      "Fitting 5 folds for each of 540 candidates, totalling 2700 fits\n",
      "Best parameters for Random Forest: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Root Mean Squared Error (RMSE) on test set: 147.91881633792644\n",
      "R-squared on test set: 0.24320107355762277\n",
      "Mean Absolute Error (MAE) on test set: 58.240695540301104\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('imputed_data_7.csv')\n",
    "X = data.drop(columns=['Price']).values\n",
    "y = data['Price'].values\n",
    "\n",
    "# Fit the LOF model to detect outliers\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "y_pred = lof.fit_predict(X)\n",
    "\n",
    "# Identify outliers\n",
    "outliers = y_pred == -1\n",
    "\n",
    "# Remove outliers from the data\n",
    "X_cleaned = X[~outliers]\n",
    "y_cleaned = y[~outliers]\n",
    "\n",
    "# Split the cleaned data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y_cleaned, test_size=0.2, random_state=13)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the parameter grid for SVR\n",
    "param_grid_svr = {\n",
    "    'svr__kernel': ['linear', 'rbf'],\n",
    "    'svr__C': [0.1, 1, 10, 100],\n",
    "    'svr__gamma': [0.1, 1, 10],\n",
    "}\n",
    "\n",
    "# Create the SVR model within a pipeline\n",
    "svr_pipeline = Pipeline([('scaler', StandardScaler()), ('svr', SVR())])\n",
    "\n",
    "# Perform GridSearchCV to find the best hyperparameters for SVR\n",
    "grid_search_svr = GridSearchCV(estimator=svr_pipeline, param_grid=param_grid_svr, cv=5, scoring='neg_mean_squared_error', verbose=1)\n",
    "grid_search_svr.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters for SVR\n",
    "best_params_svr = grid_search_svr.best_params_\n",
    "print(\"Best parameters for SVR:\", best_params_svr)\n",
    "svr_best = SVR(kernel=best_params_svr['svr__kernel'], C=best_params_svr['svr__C'], gamma=best_params_svr['svr__gamma'])\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500],\n",
    "    \"max_depth\": [None, 5, 10, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [None, \"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV to find the best hyperparameters for Random Forest\n",
    "grid_search_rf = GridSearchCV(estimator=RandomForestRegressor(random_state=13), param_grid=param_grid_rf, cv=5, scoring='neg_mean_squared_error', verbose=1)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters for Random Forest\n",
    "best_params_rf = grid_search_rf.best_params_\n",
    "print(\"Best parameters for Random Forest:\", best_params_rf)\n",
    "rf_best = RandomForestRegressor(**best_params_rf, random_state=13)\n",
    "\n",
    "# Create the ensemble model using VotingRegressor\n",
    "voting_regressor = VotingRegressor(estimators=[\n",
    "    ('svr', svr_best),\n",
    "    ('random_forest', rf_best)\n",
    "], weights=[2, 1])  # Adjust weights based on performance of individual models\n",
    "\n",
    "# Train the ensemble model\n",
    "voting_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = voting_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Root Mean Squared Error (RMSE) on test set:\", rmse)\n",
    "print(\"R-squared on test set:\", r_squared)\n",
    "print(\"Mean Absolute Error (MAE) on test set:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtained the most correlated features from using RFECV\n",
    "features = ['Bedrooms', 'Bathrooms', 'Location', 'PoolQuality', 'HasPhotovoltaics',\n",
    "       'HasFiberglass', 'IsFurnished', 'HouseColor', 'HasFireplace',\n",
    "       'KitchensQuality', 'BathroomsQuality', 'BedroomsQuality',\n",
    "       'LivingRoomsQuality', 'SquareFootageGarden', 'PreviousOwnerRating',\n",
    "       'HeatingCosts', 'WindowModelNames']\n",
    "target = 'Price'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test set: 63.380839187962565\n",
      "R-squared on test set: 0.5637655445174128\n",
      "Mean Absolute Error (MAE) on test set: 48.75822068267942\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('imputed_data_7.csv')\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "# Fit the LOF model to detect outliers\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "y_pred = lof.fit_predict(X)\n",
    "\n",
    "# Identify outliers\n",
    "outliers = y_pred == -1\n",
    "\n",
    "# Remove outliers from the data\n",
    "X_cleaned = X[~outliers]\n",
    "y_cleaned = y[~outliers]\n",
    "\n",
    "# Split the cleaned data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cleaned, y_cleaned, test_size=0.2, random_state=13)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Use the provided best parameters for SVR\n",
    "svr_best = SVR(kernel='linear', C=100, gamma=0.1)\n",
    "\n",
    "# Use the provided best parameters for Random Forest\n",
    "rf_best = RandomForestRegressor(\n",
    "    n_estimators=100, \n",
    "    max_depth=None, \n",
    "    max_features='sqrt', \n",
    "    min_samples_leaf=2, \n",
    "    min_samples_split=5, \n",
    "    random_state=13\n",
    ")\n",
    "\n",
    "# Create the ensemble model using VotingRegressor\n",
    "voting_regressor = VotingRegressor(estimators=[\n",
    "    ('svr', svr_best),\n",
    "    ('random_forest', rf_best)\n",
    "], weights=[2, 1])  # Adjust weights based on performance of individual models\n",
    "\n",
    "# Train the ensemble model\n",
    "voting_regressor.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = voting_regressor.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Root Mean Squared Error (RMSE) on test set:\", rmse)\n",
    "print(\"R-squared on test set:\", r_squared)\n",
    "print(\"Mean Absolute Error (MAE) on test set:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Evaluation on Test Set:\n",
      "Root Mean Squared Error (RMSE) on test set: 51.84816037724185\n",
      "R-squared on test set: 0.7080753970299145\n",
      "Mean Absolute Error (MAE) on test set: 39.67402065908165\n",
      "\n",
      "Cross-Validation Results:\n",
      "Mean Squared Error (MSE) on test set: 172961.36934662558\n",
      "Mean Absolute Error (MAE) on test set: 86.36790467500896\n",
      "R-squared on test set: 0.07826636695894071\n",
      "Root Mean Squared Error (RMSE) on test set: 376.8815888040527\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('imputed_data_7.csv')\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "# Fit the LOF model to detect outliers\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "y_pred = lof.fit_predict(X)\n",
    "\n",
    "# Identify outliers\n",
    "outliers = y_pred == -1\n",
    "\n",
    "# Remove outliers from the data\n",
    "X_cleaned = X[~outliers]\n",
    "y_cleaned = y[~outliers]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_cleaned_scaled = scaler.fit_transform(X_cleaned)\n",
    "\n",
    "# Use the provided best parameters for SVR\n",
    "svr_best = SVR(kernel='linear', C=100, gamma=0.1)\n",
    "\n",
    "# Use the provided best parameters for Random Forest\n",
    "rf_best = RandomForestRegressor(\n",
    "    n_estimators=100, \n",
    "    max_depth=None, \n",
    "    max_features='sqrt', \n",
    "    min_samples_leaf=2, \n",
    "    min_samples_split=5, \n",
    "    random_state=13\n",
    ")\n",
    "\n",
    "# Create the ensemble model using VotingRegressor\n",
    "voting_regressor = VotingRegressor(estimators=[\n",
    "    ('svr', svr_best),\n",
    "    ('random_forest', rf_best)\n",
    "], weights=[5,1]) \n",
    "\n",
    "def rmse_scorer(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# Training the ensemble model on the training set\n",
    "voting_regressor.fit(X_cleaned_scaled, y_cleaned)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_cleaned_scaled, y_cleaned, test_size=0.2, random_state=13)\n",
    "voting_regressor.fit(X_train, y_train)\n",
    "y_pred = voting_regressor.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5\n",
    "r_squared = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"\\nEvaluation on Test Set:\")\n",
    "print(\"Root Mean Squared Error (RMSE) on test set:\", rmse)\n",
    "print(\"R-squared on test set:\", r_squared)\n",
    "print(\"Mean Absolute Error (MAE) on test set:\", mae)\n",
    "\n",
    "# Evaluate the ensemble model using cross-validation\n",
    "scoring = {\n",
    "    'mse': make_scorer(mean_squared_error),\n",
    "    'mae': make_scorer(mean_absolute_error),\n",
    "    'r2': make_scorer(r2_score),\n",
    "    'rmse': make_scorer(rmse_scorer)\n",
    "}\n",
    "cv_results = cross_validate(voting_regressor, X_cleaned_scaled, y_cleaned, cv=5, scoring=scoring, return_train_score=True)\n",
    "\n",
    "print(\"\\nCross-Validation Results:\")\n",
    "print(f\"Mean Squared Error (MSE) on test set: {np.mean(cv_results['test_mse'])}\")\n",
    "print(f\"Mean Absolute Error (MAE) on test set: {np.mean(cv_results['test_mae'])}\")\n",
    "print(f\"R-squared on test set: {np.mean(cv_results['test_r2'])}\")\n",
    "print(f\"Root Mean Squared Error (RMSE) on test set: {np.mean(cv_results['test_rmse'])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
